{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataCamp Network Analysis in Python: Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network: Nodes connected by Edges to form a Network/Graph\n",
    "- Nodes contain information\n",
    "- as do Edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NetworkX API - manipulate and analyze network data with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'list'>]\n",
      "[(1, 2)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "#create a network graph incidence\n",
    "G = nx.Graph()\n",
    "\n",
    "#add nodes\n",
    "G.add_nodes_from([list])\n",
    "\n",
    "#view nodes present\n",
    "print(G.nodes())\n",
    "\n",
    "#add edges\n",
    "G.add_edge(1,2)\n",
    "\n",
    "#view edges present\n",
    "print(G.edges())\n",
    "\n",
    "#assign value to node\n",
    "G.node[1]['label'] = 'blue'\n",
    "\n",
    "#return a tuple (node1, dict{'label':'blue'}) of network\n",
    "G.nodes(data=True)\n",
    "\n",
    "#plot network: node/link diagram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nx.draw(G)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ex: Twitter network comes from KONECT, and shows a snapshot of a subset of Twitter users. It is an anonymized Twitter network with metadata. You can use the NetworkX API to explore some basic properties of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format: [ output expression for iterator variable in iterable if predicate expression ]\n",
    "\n",
    "# Use a list comprehension to get the nodes of interest: noi\n",
    "noi = [n for n, d in T.nodes(data=True) if d['occupation'] == 'scientist']\n",
    "\n",
    "# Use a list comprehension to get the edges of interest: eoi\n",
    "eoi = [(u, v) for u, v, d in T.edges(data=True) if d['date'] < date(2010, 1, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undirected Graphs: Networks with Edges that have no inherent directionality\n",
    "- ie. Facebook\n",
    "- Graphs Type = Graph\n",
    "\n",
    "#### Directed Graphs: Networks with Edges that have directionality (vectors)\n",
    "- ie. Twitter\n",
    "- Graphs Type = DiGraph\n",
    "\n",
    "#### Multiple Undirected/Directed Graphs: Networks with MULTIPLE Edges that do not/do have directionality (vectors)\n",
    "- ie. Trip record between bike sharing stations\n",
    "- Graphs Type = MultiGraph (no directionality)\n",
    "OR\n",
    "- Graphs Type = MultiDiGraph (directionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undirected Graph\n",
    "G = nx.Graph()\n",
    "\n",
    "#assess type of graph\n",
    "print(type(G))\n",
    "\n",
    "# Directed Graph\n",
    "D = nx.DiGraph()\n",
    "\n",
    "#assess type of graph\n",
    "print(type(D))\n",
    "\n",
    "# Multi-Undirected Graph\n",
    "M = nx.MultiGraph()\n",
    "\n",
    "#assess type of graph\n",
    "print(type(M))\n",
    "\n",
    "# Multi-Directed Graph\n",
    "MD = nx.MultiDiGraph()\n",
    "\n",
    "#assess type of graph\n",
    "print(type(MD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edges Properties:\n",
    "- can be WEIGHTED (hold a value)\n",
    "- can be SELF-CONTAINED (loops back to the Node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set edge weight format: network_name.edges[node1, node2]['attribute'] = value\n",
    "T.edges[1,2]['weight'] = 2\n",
    "\n",
    "# Set the weight of the edge\n",
    "T[1][10]['weight'] = 2\n",
    "\n",
    "# Iterate over all the edges (with metadata)\n",
    "for u, v, d in T.edges(data=True):\n",
    "\n",
    "    # Check if node 293 is involved\n",
    "    if 293 in [u,v]:\n",
    "\n",
    "        # Set the weight to 1.1\n",
    "        T[u][v]['weight'] = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether there are self-loops in the graph\n",
    "\n",
    "# Define find_selfloop_nodes()\n",
    "def find_selfloop_nodes(G):\n",
    "    \"\"\"\n",
    "    Finds all nodes that have self-loops in the graph G.\n",
    "    \"\"\"\n",
    "    nodes_in_selfloops = []\n",
    "\n",
    "    # Iterate over all the edges of G\n",
    "    for u, v in G.edges():\n",
    "\n",
    "    # Check if node u and node v are the same\n",
    "        if u == v:\n",
    "\n",
    "            # Append node u to nodes_in_selfloops\n",
    "            nodes_in_selfloops.append(u)\n",
    "\n",
    "    return nodes_in_selfloops\n",
    "\n",
    "# Check whether number of self loops equals the number of nodes in self loops\n",
    "assert T.number_of_selfloops() == len(find_selfloop_nodes(T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Visualization \n",
    "- **Matrix Plots**: Visualize Clusters/Communities of Nodes\n",
    "    - Nodes = Rows/Columns\n",
    "    - Cells -> filled in based on whether an Edge exists between the Nodes\n",
    "    - *Undirected Graph*: Matrix is symmetrical around the diagnal of the matrix\n",
    "    - *Directed Graph*: Matrix cell is filled in based on directionality\n",
    "- **Arc Plot**: Visualize Relationship Between Connectivity and Sorted(Grouped) Property\n",
    "    - Transformation of Node/Link Diagram to nodes ordered along one axis\n",
    "    - Edges are drawn in arches from one node to another\n",
    "- **Circos Plot**\n",
    "    - Transformation of an Arc plot into a Circle\n",
    "    - Designed for Genomics: Asthetic, Compact Alternative to Arc plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nxviz as nv\n",
    "\n",
    "# Instantiate Arc Plot object\n",
    "ap = nv.ArcPlot(G)\n",
    "\n",
    "ap.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Nodes that are Important in the Network:\n",
    "- **Degree Centrality**:\n",
    "    - Concept: More Important therefore More Node Neighbors\n",
    "    - total number of neighbors Node *has* / total number of neightbors Node *can have*\n",
    "- **Betweenness Centrality**\n",
    "    - Concept: Captures bottleneck nodes in a graph \n",
    "    - the number of shortests paths through node / all possible shorests paths\n",
    "       - ex. bridging of two networks/communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of edges and nodes\n",
    "G.edges()\n",
    "\n",
    "# assess how many neighbors a node has\n",
    "G.neighbors(node)\n",
    "\n",
    "# Degree of Centrality *score* -> key:value of node:score\n",
    "nx.degree_centrality(G)\n",
    "#NOTE: self-loops are not considered\n",
    "\n",
    "# Compute number of neighbors for each node\n",
    "\n",
    "# Define nodes_with_m_nbrs()\n",
    "def nodes_with_m_nbrs(G, m):\n",
    "    \"\"\"\n",
    "    Returns all nodes in graph G that have m neighbors.\n",
    "    \"\"\"\n",
    "    nodes = set()\n",
    "\n",
    "    # Iterate over all nodes in G\n",
    "    for n in G.nodes():\n",
    "\n",
    "        # Check if the number of neighbors of n matches m\n",
    "        if len(list(G.neighbors(n))) == m:\n",
    "\n",
    "            # Add the node n to the set\n",
    "            nodes.add(n)\n",
    "\n",
    "    # Return the nodes with m neighbors\n",
    "    return nodes\n",
    "\n",
    "# Compute and print all nodes in T that have 6 neighbors\n",
    "six_nbrs = nodes_with_m_nbrs(T, 6)\n",
    "print(six_nbrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Degree Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the degree of every node: degrees\n",
    "degrees = [len(list(T.neighbors(n))) for n in T.nodes()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Algorithms \n",
    "- Path Finding\n",
    "    - Optimization: calculating the shortest transport path between nodes\n",
    "        - *Breadth-Search First (BSF)*: Find the shortest path \n",
    "    - Modeling: disease spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path_exists()\n",
    "def path_exists(G, node1, node2):\n",
    "    \"\"\"\n",
    "    This function checks whether a path exists between two nodes (node1, node2) in graph G.\n",
    "    \"\"\"\n",
    "    visited_nodes = set()\n",
    "    queue = [node1]\n",
    "\n",
    "    for node in queue:\n",
    "        neighbors = G.neighbors(node)\n",
    "        if node2 in neighbors:\n",
    "            print('Path exists between nodes {0} and {1}'.format(node1, node2))\n",
    "            return True\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            visited_nodes.add(node)\n",
    "            queue.extend([n for n in neighbors if n not in visited_nodes])\n",
    "\n",
    "        # Check to see if the final element of the queue has been reached\n",
    "        if node == queue[-1]:\n",
    "            print('Path does not exist between nodes {0} and {1}'.format(node1, node2))\n",
    "\n",
    "            # Place the appropriate return statement\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betweenness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a barbell graph\n",
    "# m1 - number of nodes in the barbell ends\n",
    "# m2 - number of nodes in the barbell bridge\n",
    "G = nx.barbell_graph(m1=5, m2=1)\n",
    "\n",
    "# Betweeness Centrality\n",
    "nx.betweenness_centrality(G) # returns dictionary key:value, node:score\n",
    "\n",
    "# ---- Find Node with Highest Degree Centrality -- Function ---- \n",
    "\n",
    "# Define find_nodes_with_highest_deg_cent()\n",
    "def find_nodes_with_highest_deg_cent(G):\n",
    "\n",
    "    # Compute the degree centrality of G: deg_cent\n",
    "    deg_cent = nx.degree_centrality(G)\n",
    "\n",
    "    # Compute the maximum degree centrality: max_dc\n",
    "    max_dc = max(list(deg_cent.values()))\n",
    "\n",
    "    nodes = set()\n",
    "\n",
    "    # Iterate over the degree centrality dictionary\n",
    "    for k, v in deg_cent.items():\n",
    "\n",
    "        # Check if the current value has the maximum degree centrality\n",
    "        if v == max_dc:\n",
    "\n",
    "            # Add the current node to the set of nodes\n",
    "            nodes.add(k)\n",
    "\n",
    "    return nodes\n",
    "\n",
    "# Find the node(s) that has the highest degree centrality in T: top_dc\n",
    "top_dc = find_nodes_with_highest_deg_cent(T)\n",
    "print(top_dc)\n",
    "\n",
    "# Write the assertion statement\n",
    "for node in top_dc:\n",
    "    assert nx.degree_centrality(T)[node] == max(nx.degree_centrality(T).values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structures and Subgraphs\n",
    "- Cliques & Communities\n",
    "    - Edge = simpliest clique possible\n",
    "    - Triangle = simpliest clique community\n",
    "        - ex. Friend recommendation systems\n",
    "- Subgraphs (in context of Cliques)\n",
    "    - visualize portions of a larger graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clique code\n",
    "from itertools import combinations\n",
    "\n",
    "# Iternate over every pair of nodes in the network\n",
    "# combinations( sequence, size of sequence )\n",
    "for n1, n2, in combinations(G.nodes(), 2):\n",
    "    print(n1, n2)\n",
    "\n",
    "# Find Cliques\n",
    "nx.find_cliques(G) # generator object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subgraphs\n",
    "\n",
    "# Generate graph G probabilistically\n",
    "G = nx.erdos_renyi_graph(n=20, p=0.2)\n",
    "\n",
    "# Select a portion of G\n",
    "nodes = G.neighbors(8)\n",
    "nodes.append(8)\n",
    "\n",
    "# Make a subgraph\n",
    "G_eight = G.subgraph(nodes)\n",
    "\n",
    "# Draw subgraph\n",
    "nx.draw(G_eight, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study: Github User Collaboration Network\n",
    "- **Nodes = Users**\n",
    "- **Edges = Collaboration on same Github repository**\n",
    "### Goal: \n",
    "    - Analyze Structure\n",
    "    - Visualize\n",
    "    - Build Simple Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Characterizing the network -----\n",
    "\n",
    "# Determine size of G\n",
    "len(G.nodes()), len(G.edges())\n",
    "\n",
    "# Import necessary modules\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Plot the degree distribution of the GitHub collaboration network\n",
    "plt.hist(list(nx.degree_centrality(G).values()))\n",
    "plt.show()\n",
    "\n",
    "# Plot the degree distribution of the GitHub collaboration network\n",
    "plt.hist(list(nx.betweenness_centrality(G).values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Network Visualization -----\n",
    "\n",
    "# Import necessary modules -- Matrix Plot --\n",
    "from nxviz import MatrixPlot\n",
    "\n",
    "# Calculate the largest connected component subgraph: largest_ccs\n",
    "largest_ccs = sorted(nx.connected_component_subgraphs(G), key=lambda x: len(x))[-1]\n",
    "\n",
    "# Create the customized MatrixPlot object: h\n",
    "h = MatrixPlot(largest_ccs, node_grouping='grouping')\n",
    "\n",
    "# Draw the MatrixPlot to the screen\n",
    "h.draw()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Import necessary modules -- ArcPlot --\n",
    "from nxviz.plots import ArcPlot\n",
    "\n",
    "# Iterate over all the nodes in G, including the metadata\n",
    "for n, d in G.nodes(data=True):\n",
    "\n",
    "    # Calculate the degree of each node: G.node[n]['degree']\n",
    "    G.node[n]['degree'] = nx.degree(G, n)\n",
    "\n",
    "# Create the ArcPlot object: a\n",
    "a = ArcPlot(G, node_order='degree')\n",
    "\n",
    "# Draw the ArcPlot to the screen\n",
    "a.draw()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Import necessary modules -- CircosPlot --\n",
    "from nxviz import CircosPlot\n",
    "\n",
    "# Iterate over all the nodes, including the metadata\n",
    "for n, d in G.nodes(data=True):\n",
    "\n",
    "    # Calculate the degree of each node: G.node[n]['degree']\n",
    "    G.node[n]['degree'] = nx.degree(G,n)\n",
    "\n",
    "# Create the CircosPlot object: c\n",
    "c = CircosPlot(G, node_order='degree', node_grouping='grouping', node_color='grouping')\n",
    "\n",
    "# Draw the CircosPlot object to the screen\n",
    "c.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Network Cliques -----\n",
    "\n",
    "# Calculate the maximal cliques in G: cliques\n",
    "cliques = nx.find_cliques(G)\n",
    "\n",
    "# Count and print the number of maximal cliques in G\n",
    "print(len(list(cliques)))\n",
    "\n",
    "# Import necessary modules -- CircosPlot\n",
    "import networkx as nx\n",
    "from nxviz import CircosPlot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Find the author(s) that are part of the largest maximal clique: largest_clique\n",
    "largest_clique = sorted(nx.find_cliques(G), key=lambda x:len(x))[-1]\n",
    "\n",
    "# Create the subgraph of the largest_clique: G_lc\n",
    "G_lc = G.subgraph(largest_clique)\n",
    "\n",
    "# Create the CircosPlot object: c\n",
    "c = CircosPlot(G_lc)\n",
    "\n",
    "# Draw the CircosPlot to the screen\n",
    "c.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Build Simple Recommendation System, Step 1: Find Important Users -----\n",
    "\n",
    "# Compute the degree centralities of G: deg_cent\n",
    "deg_cent = nx.degree_centrality(G)\n",
    "\n",
    "# Compute the maximum degree centrality: max_dc\n",
    "max_dc = max(deg_cent.values())\n",
    "\n",
    "# Find the user(s) that have collaborated the most: prolific_collaborators\n",
    "prolific_collaborators = [n for n, dc in deg_cent.items() if dc == max_dc]\n",
    "\n",
    "# Print the most prolific collaborator(s)\n",
    "print(prolific_collaborators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Build Simple Recommendation System, Step 2: Find Largest Communities of Collaborators -----\n",
    "\n",
    "# Import necessary modules -- ArcPlot --\n",
    "from nxviz import ArcPlot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Identify the largest maximal clique: largest_max_clique\n",
    "largest_max_clique = set(sorted(nx.find_cliques(G), key=lambda x: len(x))[-1])\n",
    "\n",
    "# Create a subgraph from the largest_max_clique: G_lmc\n",
    "G_lmc = G.subgraph(largest_max_clique).copy()  \n",
    "\n",
    "# Go out 1 degree of separation\n",
    "for node in list(G_lmc.nodes()):\n",
    "    G_lmc.add_nodes_from(G.neighbors(node))\n",
    "    G_lmc.add_edges_from(zip([node]*len(list(G.neighbors(node))), G.neighbors(node)))\n",
    "\n",
    "# Record each node's degree centrality score\n",
    "for n in G_lmc.nodes():\n",
    "    G_lmc.node[n]['degree centrality'] = nx.degree_centrality(G_lmc)[n]\n",
    "\n",
    "# Create the ArcPlot object: a\n",
    "a = ArcPlot(G_lmc, node_order='degree centrality')\n",
    "\n",
    "# Draw the ArcPlot to the screen\n",
    "a.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Build Simple Recommendation System, Step 3: Build Collaboration Recommendation System -----\n",
    "\n",
    "# Import necessary modules\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "# Initialize the defaultdict: recommended\n",
    "recommended = defaultdict(int)\n",
    "\n",
    "# Iterate over all the nodes in G\n",
    "for n, d in G.nodes(data=True):\n",
    "\n",
    "    # Iterate over all possible triangle relationship combinations\n",
    "    for n1, n2 in combinations(G.neighbors(n), 2):\n",
    "\n",
    "        # Check whether n1 and n2 do not have an edge\n",
    "        if not G.has_edge(n1, n2):\n",
    "\n",
    "            # Increment recommended\n",
    "            recommended[(n1, n2)] += 1\n",
    "\n",
    "# Identify the top 10 pairs of users\n",
    "all_counts = sorted(recommended.values())\n",
    "top10_pairs = [pair for pair, count in recommended.items() if count > all_counts[-10]]\n",
    "print(top10_pairs)\n",
    "\n",
    "\n",
    "# --- Characterize Network ---\n",
    "\n",
    "# Plot the degree distribution of the GitHub collaboration network\n",
    "plt.hist(list(nx.degree_centrality(G).values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataCamp Network Analysis in Python: Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bipartite graphs\n",
    "- Condition 1: \n",
    "    - Graph is partitioned into 2 sets\n",
    "- Condition 2: \n",
    "    - Nodes are only connected to nodes in other partitions\n",
    "##### In contrast to 'Unipartite' graphs (used earlier)\n",
    "\n",
    "ex. Customers (partition 1) and Purchases (partition 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "#create a network graph incidence\n",
    "G = nx.Graph()\n",
    "\n",
    "#define contents for bipartite 1\n",
    "numbers = range(3)\n",
    "\n",
    "#add nodes - define bipartite 1 label as part of the nodes metadata\n",
    "G.add_nodes_from(numbers, bipartite='customers')\n",
    "\n",
    "#define contents for bipartite 2\n",
    "letters = ['a', 'b']\n",
    "\n",
    "#add nodes - define bipartite 2 label as part of the nodes metadata\n",
    "G.add_nodes_from(letters, bipartite='products')\n",
    "\n",
    "#visualize contents\n",
    "G.nodes(data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bipartite Degree Centrality**: \n",
    "total number of neighbors Node has / total number of neightbors Nodes in the *opposite bipartite* can have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a specific bipartite group\n",
    "customer_nodes = [n for n, d in G.nodes(data=True) if d['bipartite'] == 'customers']\n",
    "\n",
    "# Define get_nodes_from_partition()\n",
    "def get_nodes_from_partition(G, partition):\n",
    "    # Initialize an empty list for nodes to be returned\n",
    "    nodes = []\n",
    "    # Iterate over each node in the graph G\n",
    "    for n in G.nodes(data=False):\n",
    "        # Check that the node belongs to the particular partition\n",
    "        if G.node[n]['bipartite'] == partition:\n",
    "            # If so, append it to the list of nodes\n",
    "            nodes.append(n)\n",
    "    return nodes\n",
    "\n",
    "# Print the number of nodes in the 'projects' partition\n",
    "print(len(get_nodes_from_partition(G, 'projects')))\n",
    "\n",
    "# Print the number of nodes in the 'users' partition\n",
    "print(len(get_nodes_from_partition(G, 'users')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Degree centrality distribution of user nodes and project nodes ---\n",
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1: Get the 'users' nodes: user_nodes\n",
    "user_nodes = get_nodes_from_partition(G, 'users')\n",
    "\n",
    "# Compute the degree centralities: dcs\n",
    "dcs = nx.degree_centrality(G)\n",
    "\n",
    "# Get the degree centralities for user_nodes: user_dcs\n",
    "user_dcs = [dcs[n] for n in user_nodes]\n",
    "\n",
    "# Plot the degree distribution of users_dcs\n",
    "plt.yscale('log')\n",
    "plt.hist(user_dcs, bins=20)\n",
    "plt.show()\n",
    "\n",
    "# 2: Get the 'projects' nodes: project_nodes\n",
    "project_nodes = get_nodes_from_partition(G, 'projects')\n",
    "\n",
    "# Compute the degree centralities: dcs\n",
    "dcs = nx.degree_centrality(G)\n",
    "\n",
    "# Get the degree centralities for project_nodes: project_dcs\n",
    "project_dcs = [dcs[n] for n in project_nodes]\n",
    "\n",
    "# Plot the degree distribution of project_dcs\n",
    "plt.yscale('log')\n",
    "plt.hist(project_dcs, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Recommendation Systems ---\n",
    "\n",
    "# Shared nodes in other partition\n",
    "def shared_partition_nodes(G, node1, node2):\n",
    "    # Check that the nodes belong to the same partition\n",
    "    assert G.node[node1]['bipartite'] == G.node[node2]['bipartite']\n",
    "\n",
    "    # Get neighbors of node 1: nbrs1\n",
    "    nbrs1 = G.neighbors(node1)\n",
    "    # Get neighbors of node 2: nbrs2\n",
    "    nbrs2 = G.neighbors(node2)\n",
    "\n",
    "    # Compute the overlap using set intersections\n",
    "    overlap = set(nbrs1).intersection(nbrs2)\n",
    "    return overlap\n",
    "\n",
    "# Print the number of shared repositories between users 'u7909' and 'u2148'\n",
    "print(len(shared_partition_nodes(G, 'u7909', 'u2148')))\n",
    "\n",
    "# User similarity metric\n",
    "def user_similarity(G, user1, user2, proj_nodes):\n",
    "    # Check that the nodes belong to the 'users' partition\n",
    "    assert G.node[user1]['bipartite'] == 'users'\n",
    "    assert G.node[user2]['bipartite'] == 'users'\n",
    "\n",
    "    # Get the set of nodes shared between the two users\n",
    "    shared_nodes = shared_partition_nodes(G, user1, user2)\n",
    "\n",
    "    # Return the fraction of nodes in the projects partition\n",
    "    return len(shared_nodes) / len(proj_nodes)\n",
    "\n",
    "# Compute the similarity score between users 'u4560' and 'u1880'\n",
    "project_nodes = get_nodes_from_partition(G, 'projects')\n",
    "similarity_score = user_similarity(G,'u4560', 'u1880', project_nodes)\n",
    "print(similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Similar Users\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def most_similar_users(G, user, user_nodes, proj_nodes):\n",
    "    # Data checks\n",
    "    assert G.node[user]['bipartite'] == 'users'\n",
    "\n",
    "    # Get other nodes from user partition\n",
    "    user_nodes = set(user_nodes)\n",
    "    user_nodes.remove(user)\n",
    "\n",
    "    # Create the dictionary: similarities\n",
    "    similarities = defaultdict(list)\n",
    "    for n in user_nodes:\n",
    "        similarity = user_similarity(G, user, n, proj_nodes)\n",
    "        similarities[similarity].append(n)\n",
    "\n",
    "    # Compute maximum similarity score: max_similarity\n",
    "    max_similarity = max(similarities.keys())\n",
    "\n",
    "    # Return list of users that share maximal similarity\n",
    "    return similarities[max_similarity]\n",
    "\n",
    "user_nodes = get_nodes_from_partition(G, 'users')\n",
    "project_nodes = get_nodes_from_partition(G, 'projects')\n",
    "\n",
    "print(list(most_similar_users(G, 'u4560', user_nodes, project_nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find recommended repositories\n",
    "\n",
    "def recommend_repositories(G, from_user, to_user):\n",
    "    # Get the set of repositories that from_user has contributed to\n",
    "    from_repos = set(G.neighbors(from_user))\n",
    "    # Get the set of repositories that to_user has contributed to\n",
    "    to_repos = set(G.neighbors(to_user))\n",
    "\n",
    "    # Identify repositories that the from_user is connected to that the to_user is not connected to\n",
    "    return from_repos.difference(to_repos)\n",
    "\n",
    "# Print the repositories to be recommended\n",
    "print(recommend_repositories(G, 'u7909', 'u2148'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Network Data\n",
    "(node 1) (node 2) {meta data dictionary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Digest text network data into a graph in memory\n",
    "G = nx.read_edgelist('----.txt')\n",
    "\n",
    "# Query graph\n",
    "G.edges(data=True)[0:5]\n",
    "\n",
    "# --- Bipartite Projection ---\n",
    "cust_nodes = [n for n in G.nodes() if G.node[n] ['bipartite'] == 'customers']\n",
    "\n",
    "# Projections\n",
    "G_cust = nx.bipartite.projected_graph(G, cust_nodes)\n",
    "\n",
    "# Degree centrality\n",
    "G_cust_dc = nx.bipartite.degree_centrality(G, cust_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Graphs\n",
    "# Import networkx\n",
    "import networkx as nx\n",
    "\n",
    "# Read in the data: g\n",
    "G = nx.read_edgelist('american-revolution.edgelist')\n",
    "\n",
    "# Assign nodes to 'clubs' or 'people' partitions\n",
    "for n, d in G.nodes(data=True):\n",
    "    if '.' in n:\n",
    "        G.node[n]['bipartite'] = 'people'\n",
    "    else:\n",
    "        G.node[n]['bipartite'] = 'clubs'\n",
    "        \n",
    "# Print the edges of the graph\n",
    "print(G.edges())\n",
    "\n",
    "# Computing Projections\n",
    "# Prepare the nodelists needed for computing projections: people, clubs\n",
    "people = [n for n in G.nodes() if G.node[n]['bipartite'] == 'people']\n",
    "clubs = [n for n, d in G.nodes(data=True) if d['bipartite'] == 'clubs']\n",
    "\n",
    "# Compute the people and clubs projections: peopleG, clubsG\n",
    "peopleG = nx.bipartite.projected_graph(G, people)\n",
    "clubsG = nx.bipartite.projected_graph(G, clubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the degree centrality distribution of both node partitions from the original graph\n",
    "plt.figure()\n",
    "original_dc = nx.bipartite.degree_centrality(G, people)\n",
    "plt.hist(list(original_dc.values()), alpha=0.5)\n",
    "plt.yscale('log')\n",
    "plt.title('Bipartite degree centrality')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the degree centrality distribution of the peopleG graph\n",
    "plt.figure()  \n",
    "people_dc = nx.degree_centrality(peopleG)\n",
    "plt.hist(list(people_dc.values()))\n",
    "plt.yscale('log')\n",
    "plt.title('Degree centrality of people partition')\n",
    "plt.show()\n",
    "\n",
    "# Plot the degree centrality distribution of the clubsG graph\n",
    "plt.figure() \n",
    "clubs_dc = nx.degree_centrality(clubsG)\n",
    "plt.hist(list(clubs_dc.values()))\n",
    "plt.yscale('log')\n",
    "plt.title('Degree centrality of clubs partition')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bipartite graph adjacency matrices:\n",
    "- often asymmetric because there are more ways to construct an asymmetric bipartite graph than a symmetric one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of people and list of clubs from the graph: people_nodes, clubs_nodes\n",
    "people_nodes = get_nodes_from_partition(G, 'people')\n",
    "clubs_nodes = get_nodes_from_partition(G, 'clubs')\n",
    "\n",
    "# Compute the biadjacency matrix: bi_matrix\n",
    "bi_matrix = nx.bipartite.biadjacency_matrix(G, row_order=people_nodes, column_order=clubs_nodes)\n",
    "\n",
    "# Compute the user-user projection: user_matrix\n",
    "user_matrix = bi_matrix @ bi_matrix.T\n",
    "\n",
    "# --- Find shared membership: Transposition ---\n",
    "import numpy as np\n",
    "\n",
    "# Find out the names of people who were members of the most number of clubs\n",
    "diag = user_matrix.diagonal() \n",
    "indices = np.where(diag == diag.max())[0]  \n",
    "print('Number of clubs: {0}'.format(diag.max()))\n",
    "print('People with the most number of memberships:')\n",
    "for i in indices:\n",
    "    print('- {0}'.format(people_nodes[i]))\n",
    "\n",
    "# Set the diagonal to zero and convert it to a coordinate matrix format\n",
    "user_matrix.setdiag(0)\n",
    "users_coo = user_matrix.tocoo()\n",
    "\n",
    "# Find pairs of users who shared membership in the most number of clubs\n",
    "indices = np.where(users_coo.data == users_coo.data.max())[0]\n",
    "print('People with most number of shared memberships:')\n",
    "for idx in indices:\n",
    "    print('- {0}, {1}'.format(people_nodes[users_coo.row[idx]], people_nodes[users_coo.col[idx]])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store network data into a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list variable for nodes\n",
    "nodes_list = []\n",
    "\n",
    "for n, d in G.nodes(data=True):\n",
    "    node_data = dict()\n",
    "    node_data['node'] = n\n",
    "    node_data.update(d)\n",
    "    node_list.append(node_data)\n",
    "\n",
    "\n",
    "# Initialize a list to store each edge as a record: nodelist\n",
    "nodelist = []\n",
    "for n, d in G_people.nodes(data=True):\n",
    "    # nodeinfo stores one \"record\" of data as a dict\n",
    "    nodeinfo = {'person': n} \n",
    "    \n",
    "    # Update the nodeinfo dictionary \n",
    "    nodeinfo.update(d)\n",
    "    \n",
    "    # Append the nodeinfo to the node list\n",
    "    nodelist.append(nodeinfo)\n",
    "    \n",
    "\n",
    "# Create a pandas DataFrame of the nodelist: node_df\n",
    "node_df = pd.DataFrame(nodelist)\n",
    "print(node_df.head())\n",
    "\n",
    "\n",
    "# Initialize a list to store each edge as a record: edgelist\n",
    "edgelist = []\n",
    "for n1, n2, d in G_people.edges(data=True):\n",
    "    # Initialize a dictionary that shows edge information: edgeinfo\n",
    "    edgeinfo = {'node1':n1, 'node2':n2}\n",
    "    \n",
    "    # Update the edgeinfo data with the edge metadata\n",
    "    edgeinfo.update(d)\n",
    "    \n",
    "    # Append the edgeinfo to the edgelist\n",
    "    edgelist.append(edgeinfo)\n",
    "    \n",
    "# Create a pandas DataFrame of the edgelist: edge_df\n",
    "edge_df = pd.DataFrame(edgelist)\n",
    "print(edge_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Differences: *Analysis of Evolving Graph*\n",
    "\n",
    "\n",
    "#### Time Series Analysis\n",
    "- How a number changes as a function of time\n",
    "    - Goal: plot with goal of seeing a trend upward or downward over time\n",
    "- Rate of change over a sliding window of time\n",
    "    - Example: plot change in weight over time\n",
    "\n",
    "#### Evolving Graphs\n",
    "- Graphs that change over time\n",
    "    - Example: communication network\n",
    "**Assumption Cases**:\n",
    "1. Edges change over time (assume Nodes remain constant)\n",
    "2. Both Edges and Nodes change over time\n",
    "\n",
    "#### Graph Differences \n",
    "- Analogy: \n",
    "    - nonsymetric: set().differences(set()) = set()    \n",
    "- NetworkX\n",
    "    - nx.difference(G1, G2) #assuming G1 nodes = G2 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Differences with Python\n",
    "\n",
    "# what has changed between c1 and c2\n",
    "set(c1, c2, c3).differences(set(c2, c3, c4)) = set(c1)\n",
    "\n",
    "# what has changed between c3 and c4\n",
    "set(c2, c3, c4).differences(set(c2, c3, c3)) = set(c4)\n",
    "\n",
    "# --- List of Graphs ---\n",
    "\n",
    "import networkx as nx \n",
    "\n",
    "months = range(4, 11)\n",
    "\n",
    "# Initialize an empty list: Gs\n",
    "Gs = [] \n",
    "for month in months:\n",
    "    # Instantiate a new undirected graph: G\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add in all nodes that have ever shown up to the graph\n",
    "    G.add_nodes_from(data['sender'])\n",
    "    G.add_nodes_from(data['recipient'])\n",
    "    \n",
    "    # Filter the DataFrame so that there's only the given month\n",
    "    df_filtered = data[data['month'] == month]\n",
    "    \n",
    "    # Add edges from filtered DataFrame\n",
    "    G.add_edges_from(zip(df_filtered['sender'], df_filtered['recipient']))\n",
    "    \n",
    "    # Append G to the list of graphs\n",
    "    Gs.append(G)\n",
    "    \n",
    "print(len(Gs))\n",
    "\n",
    "# -- Graph Differences Over Time --\n",
    "# Instantiate a list of graphs that show edges removed: removed\n",
    "removed = []\n",
    "# Here's the fractional change over time\n",
    "fractional_changes = []\n",
    "window = 1  \n",
    "i = 0      \n",
    "\n",
    "for i in range(len(Gs) - window):\n",
    "    g1 = Gs[i]\n",
    "    g2 = Gs[i + window]\n",
    "        \n",
    "    # Compute graph difference here\n",
    "    added.append(nx.difference(g2, g1))   \n",
    "    removed.append(nx.difference(g1, g2))\n",
    "    \n",
    "    # Compute change in graph size over time\n",
    "    fractional_changes.append((len(g2.edges()) - len(g1.edges())) / len(g1.edges()))\n",
    "    \n",
    "# Print the fractional change\n",
    "print(fractional_changes)\n",
    "\n",
    "\n",
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "# Plot the number of edges added over time\n",
    "edges_added = [len(g.edges()) for g in added]\n",
    "plot1 = ax1.plot(edges_added, label='added', color='orange')\n",
    "\n",
    "# Plot the number of edges removed over time\n",
    "edges_removed = [len(g.edges()) for g in removed]\n",
    "plot2 = ax1.plot(edges_removed, label='removed', color='purple')\n",
    "\n",
    "# Set yscale to logarithmic scale\n",
    "ax1.set_yscale('log')  \n",
    "ax1.legend()\n",
    "\n",
    "# 2nd axes shares x-axis with 1st axes object\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot the fractional changes over time\n",
    "plot3 = ax2.plot(fractional_changes, label='fractional change', color='green')\n",
    "\n",
    "# Here, we create a single legend for both plots\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines1 + lines2, labels1 + labels2, loc=0)\n",
    "plt.axhline(0, color='green', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative Distribution Frequency (CDF) Graph\n",
    "- X: the original values of the data\n",
    "- Y: the percentage of values less than or equal to the corresponding X value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "# Create a list of the number of edges per month\n",
    "edge_sizes = [len(g.edges()) for g in Gs]\n",
    "\n",
    "# Plot edge sizes over time\n",
    "plt.plot(edge_sizes)\n",
    "plt.xlabel('Time elapsed from first month (in months).') \n",
    "plt.ylabel('Number of edges')                           \n",
    "plt.show() \n",
    "\n",
    "# Import necessary modules\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a list of degree centrality scores month-by-month\n",
    "cents = []\n",
    "for G in Gs:\n",
    "    cent = nx.degree_centrality(G)\n",
    "    cents.append(cent)\n",
    "\n",
    "\n",
    "# Plot ECDFs over time\n",
    "fig = plt.figure()\n",
    "for i in range(len(cents)):\n",
    "    x, y = ECDF(cents[i].values()) \n",
    "    plt.plot(x, y, label='Month {0}'.format(i+1)) \n",
    "plt.legend()   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Graph Summary\n",
    "- **Global**: Centrality Distribution\n",
    "- **Local**: Connectivity and Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 5 unique degree centrality scores: top_dcs\n",
    "top_dcs = sorted(set(nx.degree_centrality(G).values()), reverse=True)[0:5]\n",
    "\n",
    "# Create list of nodes that have the top 5 highest overall degree centralities\n",
    "top_connected = []\n",
    "for n, dc in nx.degree_centrality(G).items():\n",
    "    if dc in top_dcs:\n",
    "        top_connected.append(n)\n",
    "        \n",
    "# Print the number of nodes that share the top 5 degree centrality scores\n",
    "print(len(top_connected))\n",
    "\n",
    "# Import necessary modules\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Create a defaultdict in which the keys are nodes and the values are a list of connectivity scores over time\n",
    "connectivity = defaultdict(list)\n",
    "for n in top_connected:\n",
    "    for g in Gs:\n",
    "        connectivity[n].append(len(g.neighbors(n)))\n",
    "\n",
    "# Plot the connectivity for each node\n",
    "fig = plt.figure() \n",
    "for n, conn in connectivity.items(): \n",
    "    plt.plot(conn, label=n) \n",
    "plt.legend()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a graph from the pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Instantiate a new Graph: G\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes from each of the partitions\n",
    "G.add_nodes_from(data['student'], bipartite='student')\n",
    "G.add_nodes_from(data['forum'], bipartite='forum')\n",
    "\n",
    "# Add in each edge along with the date the edge was created\n",
    "for r, d in data.iterrows():\n",
    "    G.add_edge(d['student'], d['forum'], date=d['date']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the degree centrality distribution of the students projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Get the student partition's nodes: student_nodes\n",
    "student_nodes = [n for n, d in G.nodes(data=True) if d['bipartite'] == 'student']\n",
    "\n",
    "# Create the students nodes projection as a graph: G_students\n",
    "G_students = nx.bipartite.projected_graph(G, nodes=student_nodes)\n",
    "\n",
    "# Calculate the degree centrality using nx.degree_centrality: dcs\n",
    "dcs = nx.degree_centrality(G_students)\n",
    "\n",
    "# Plot the histogram of degree centrality values\n",
    "plt.hist(list(dcs.values()))\n",
    "plt.yscale('log')  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the degree centrality distribution of the forums projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import matplotlib.pyplot as plt \n",
    "import networkx as nx\n",
    "\n",
    "# Get the forums partition's nodes: forum_nodes\n",
    "forum_nodes = [n for n, d in G.nodes(data=True) if d['bipartite'] == 'forum']\n",
    "\n",
    "# Create the forum nodes projection as a graph: G_forum\n",
    "G_forum = nx.bipartite.projected_graph(G, nodes=forum_nodes)\n",
    "\n",
    "# Calculate the degree centrality using nx.degree_centrality: dcs\n",
    "dcs = nx.degree_centrality(G_forum)\n",
    "\n",
    "# Plot the histogram of degree centrality values\n",
    "plt.hist(list(dcs.values()))\n",
    "plt.yscale('log') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time filter on edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "\n",
    "# Instantiate a new graph: G_sub\n",
    "G_sub = nx.Graph()\n",
    "\n",
    "# Add nodes from the original graph\n",
    "G_sub.add_nodes_from(G.nodes(data=True))\n",
    "\n",
    "# Add edges using a list comprehension with one conditional on the edge dates, that the date of the edge is earlier than 2004-05-16.\n",
    "G_sub.add_edges_from([(u, v, d) for u, v, d in G.edges(data=True) if d['date'] < datetime(2004, 5, 16)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize filtered graph using nxviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from nxviz import CircosPlot\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute degree centrality scores of each node\n",
    "dcs = nx.bipartite.degree_centrality(G, nodes=forum_nodes)\n",
    "for n, d in G_sub.nodes(data=True):\n",
    "    G_sub.node[n]['dc'] = dcs[n]\n",
    "\n",
    "# Create the CircosPlot object: c\n",
    "c = CircosPlot(G_sub, node_color='bipartite', node_grouping='bipartite', node_order='dc')\n",
    "\n",
    "# Draw c to screen\n",
    "c.draw()\n",
    "\n",
    "# Display the plot\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot number of posts being made over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from datetime import timedelta  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define current day and timedelta of 2 days\n",
    "curr_day = dayone\n",
    "td = timedelta(days=2)\n",
    "\n",
    "# Initialize an empty list of posts by day\n",
    "n_posts = []\n",
    "while curr_day < lastday:\n",
    "    if curr_day.day == 1:\n",
    "        print(curr_day) \n",
    "    # Filter edges such that they are within the sliding time window: edges\n",
    "    edges = [(u, v, d) for u, v, d in G.edges(data=True) if d['date'] >= curr_day and d['date'] < curr_day + td]\n",
    "    \n",
    "    # Append number of edges to the n_posts list\n",
    "    n_posts.append(len(edges))\n",
    "    \n",
    "    # Increment the curr_day by the time delta\n",
    "    curr_day += td\n",
    "    \n",
    "# Create the plot\n",
    "plt.plot(n_posts)  \n",
    "plt.xlabel('Days elapsed')\n",
    "plt.ylabel('Number of posts')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the mean degree centrality day-by-day on the students partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize a new list: mean_dcs\n",
    "mean_dcs = []\n",
    "curr_day = dayone\n",
    "td = timedelta(days=2)\n",
    "\n",
    "while curr_day < lastday:\n",
    "    if curr_day.day == 1:\n",
    "        print(curr_day)  \n",
    "    # Instantiate a new graph containing a subset of edges: G_sub\n",
    "    G_sub = nx.Graph()\n",
    "    # Add nodes from G\n",
    "    G_sub.add_nodes_from(G.nodes(data=True))\n",
    "    # Add in edges that fulfill the criteria\n",
    "    G_sub.add_edges_from([(u, v, d) for u, v, d in G.edges(data=True) if d['date'] >= curr_day and d['date'] < curr_day + td])\n",
    "    \n",
    "    # Get the students projection\n",
    "    G_student_sub = nx.bipartite.projected_graph(G_sub, nodes=student_nodes)\n",
    "    # Compute the degree centrality of the students projection\n",
    "    dc = nx.degree_centrality(G_student_sub)\n",
    "    # Append mean degree centrality to the list mean_dcs\n",
    "    mean_dcs.append(np.mean(list(dc.values())))\n",
    "    # Increment the time\n",
    "    curr_day += td\n",
    "    \n",
    "plt.plot(mean_dcs)\n",
    "plt.xlabel('Time elapsed')\n",
    "plt.ylabel('Degree centrality.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the most popular forums day-by-day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from datetime import timedelta\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Instantiate a list to hold the list of most popular forums by day: most_popular_forums\n",
    "most_popular_forums = []\n",
    "# Instantiate a list to hold the degree centrality scores of the most popular forums: highest_dcs\n",
    "highest_dcs = []\n",
    "curr_day = dayone  \n",
    "td = timedelta(days=1)  \n",
    "\n",
    "while curr_day < lastday:  \n",
    "    if curr_day.day == 1: \n",
    "        print(curr_day) \n",
    "    # Instantiate new graph: G_sub\n",
    "    G_sub = nx.Graph()\n",
    "    \n",
    "    # Add in nodes from original graph G\n",
    "    G_sub.add_nodes_from(G.nodes(data=True))\n",
    "    \n",
    "    # Add in edges from the original graph G that fulfill the criteria\n",
    "    G_sub.add_edges_from([(u, v, d) for u, v, d in G.edges(data=True) if d['date'] >= curr_day and d['date'] < curr_day + td])\n",
    "    \n",
    "    # CODE CONTINUES ON NEXT EXERCISE\n",
    "    curr_day += td\n",
    "\n",
    "# Import necessary modules\n",
    "from datetime import timedelta\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "most_popular_forums = []\n",
    "highest_dcs = []\n",
    "curr_day = dayone \n",
    "td = timedelta(days=1)  \n",
    "\n",
    "while curr_day < lastday:  \n",
    "    if curr_day.day == 1:  \n",
    "        print(curr_day)  \n",
    "    G_sub = nx.Graph()\n",
    "    G_sub.add_nodes_from(G.nodes(data=True))   \n",
    "    G_sub.add_edges_from([(u, v, d) for u, v, d in G.edges(data=True) if d['date'] >= curr_day and d['date'] < curr_day + td])\n",
    "    \n",
    "    # Get the degree centrality \n",
    "    dc = nx.bipartite.degree_centrality(G_sub, forum_nodes)\n",
    "    # Filter the dictionary such that there's only forum degree centralities\n",
    "    forum_dcs = {n: dc for n, dc in dc.items() if n in forum_nodes}\n",
    "    # Identify the most popular forum(s) \n",
    "    most_popular_forum = [n for n, dc in forum_dcs.items() if dc == max(forum_dcs.values()) and dc != 0]\n",
    "    most_popular_forums.append(most_popular_forum) \n",
    "    # Store the highest dc values in highest_dcs\n",
    "    highest_dcs.append(max(forum_dcs.values()))\n",
    "    \n",
    "    curr_day += td  \n",
    "    \n",
    "plt.figure(1) \n",
    "plt.plot([len(forum) for forum in most_popular_forums], color='blue', label='Forums')\n",
    "plt.ylabel('Number of Most Popular Forums')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(highest_dcs, color='orange', label='DC Score')\n",
    "plt.ylabel('Top Degree Centrality Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
